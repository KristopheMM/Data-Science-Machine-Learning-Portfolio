# Resources

### Difference between Random Forests and Decision tree
As is implied by the names "Tree" and "Forest," a Random Forest is essentially a collection of Decision Trees. A decision tree is built on an entire dataset, using all the features/variables of interest, whereas a random forest randomly selects observations/rows and specific features/variables to build multiple decision trees from and then averages the results. After a large number of trees are built using this method, each tree "votes" or chooses the class, and the class receiving the most votes by a simple majority is the "winner" or predicted class. There are of course some more detailed differences, but this is the main conceptual difference.

- [Theory on explanation of Decision Tree and Random Forest](https://medium.com/datadriveninvestor/decision-tree-and-random-forest-e174686dd9eb)
- [Complete guide to Decision Trees(By Marco Peixeiro)](https://towardsdatascience.com/the-complete-guide-to-decision-trees-17a874301448)
